{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\Owen\\\\Desktop\\\\pmp\\\\Topic2_4470_Word_Vectors.csv',header=None,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>-0.014292</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>-0.014225</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>-0.023745</td>\n",
       "      <td>-0.005997</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.024899</td>\n",
       "      <td>0.017323</td>\n",
       "      <td>-0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>?</td>\n",
       "      <td>-0.019124</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>-0.002996</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>-0.008057</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004555</td>\n",
       "      <td>0.008343</td>\n",
       "      <td>-0.014806</td>\n",
       "      <td>-0.012592</td>\n",
       "      <td>-0.020747</td>\n",
       "      <td>-0.007772</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.021847</td>\n",
       "      <td>0.021408</td>\n",
       "      <td>-0.009102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?</td>\n",
       "      <td>-0.015925</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>-0.009196</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.007696</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.019730</td>\n",
       "      <td>-0.013710</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>-0.028078</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>''</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>-0.357776</td>\n",
       "      <td>-1.036951</td>\n",
       "      <td>0.469952</td>\n",
       "      <td>-1.611660</td>\n",
       "      <td>-0.920393</td>\n",
       "      <td>-1.047843</td>\n",
       "      <td>0.812955</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>-0.450508</td>\n",
       "      <td>-0.778890</td>\n",
       "      <td>0.135372</td>\n",
       "      <td>0.134435</td>\n",
       "      <td>-0.894964</td>\n",
       "      <td>0.506059</td>\n",
       "      <td>-1.636131</td>\n",
       "      <td>1.420139</td>\n",
       "      <td>-1.053915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proyecto</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.017918</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>-0.014756</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>-0.023745</td>\n",
       "      <td>-0.009586</td>\n",
       "      <td>-0.014421</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49346</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.015479</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>-0.005880</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009729</td>\n",
       "      <td>-0.007291</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-0.031664</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.005023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49347</th>\n",
       "      <td>ceramic-polymer</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007756</td>\n",
       "      <td>-0.011556</td>\n",
       "      <td>-0.001872</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.004234</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49348</th>\n",
       "      <td>tape-casting</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009485</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.011675</td>\n",
       "      <td>-0.012465</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.007735</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.042329</td>\n",
       "      <td>0.036488</td>\n",
       "      <td>-0.005002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49349</th>\n",
       "      <td>disc-type</td>\n",
       "      <td>-0.058460</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>-0.020420</td>\n",
       "      <td>-0.003634</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>-0.009637</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019693</td>\n",
       "      <td>-0.009310</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.006744</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>0.038439</td>\n",
       "      <td>-0.016577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>multilayered-type</td>\n",
       "      <td>-0.054010</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.017170</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012833</td>\n",
       "      <td>-0.010574</td>\n",
       "      <td>-0.030285</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>0.035376</td>\n",
       "      <td>-0.013578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49351 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5    \\\n",
       "0                      ? -0.014292  0.007838 -0.002896  0.007041  0.009640   \n",
       "1                      ? -0.019124  0.004895  0.000261 -0.002996  0.004262   \n",
       "2                      ? -0.015925  0.008959  0.012728  0.001627  0.009002   \n",
       "3                     ''  0.242879 -0.357776 -1.036951  0.469952 -1.611660   \n",
       "4               proyecto  0.006645  0.002655 -0.002004  0.011898  0.009993   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "49346                1.9 -0.002337  0.002169 -0.015479  0.009018 -0.012332   \n",
       "49347    ceramic-polymer -0.015645  0.027500  0.015190  0.001908  0.000280   \n",
       "49348       tape-casting -0.035595  0.022825 -0.005805  0.004398 -0.009485   \n",
       "49349          disc-type -0.058460  0.017930 -0.020420 -0.003634 -0.013074   \n",
       "49350  multilayered-type -0.054010  0.014619 -0.017170  0.005641 -0.005823   \n",
       "\n",
       "            6         7         8         9    ...       91        92   \\\n",
       "0      0.000983  0.005310  0.001771  0.005891  ... -0.001305 -0.001553   \n",
       "1      0.007593 -0.008057  0.016138  0.009148  ... -0.004555  0.008343   \n",
       "2     -0.009196  0.000113  0.014790  0.001011  ...  0.005379 -0.000023   \n",
       "3     -0.920393 -1.047843  0.812955  0.077639  ...  0.014267 -0.450508   \n",
       "4     -0.003337 -0.017918  0.001710  0.001841  ...  0.001581  0.004362   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "49346 -0.005880 -0.001747 -0.015124 -0.000619  ... -0.009729 -0.007291   \n",
       "49347 -0.001888  0.004398  0.010840  0.003353  ... -0.007756 -0.011556   \n",
       "49348 -0.004525 -0.005787  0.019662  0.010332  ... -0.010189 -0.011675   \n",
       "49349 -0.009637  0.006483  0.024382  0.010641  ... -0.019693 -0.009310   \n",
       "49350  0.001231  0.007013  0.018517  0.011593  ... -0.012833 -0.010574   \n",
       "\n",
       "            93        94        95        96        97        98        99   \\\n",
       "0     -0.014225  0.002071 -0.023745 -0.005997 -0.003445 -0.024899  0.017323   \n",
       "1     -0.014806 -0.012592 -0.020747 -0.007772  0.000497 -0.021847  0.021408   \n",
       "2     -0.007696 -0.004017 -0.019730 -0.013710  0.004691 -0.028078  0.021047   \n",
       "3     -0.778890  0.135372  0.134435 -0.894964  0.506059 -1.636131  1.420139   \n",
       "4     -0.014756 -0.015226 -0.023745 -0.009586 -0.014421 -0.004782  0.034854   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49346 -0.004602  0.009725  0.012778  0.003016 -0.001009 -0.031664 -0.003349   \n",
       "49347 -0.001872  0.004398 -0.009889 -0.000199 -0.004234 -0.014100  0.006598   \n",
       "49348 -0.012465  0.002276 -0.001751 -0.007735  0.009182 -0.042329  0.036488   \n",
       "49349 -0.036355  0.006278 -0.007550 -0.006744  0.019674 -0.064233  0.038439   \n",
       "49350 -0.030285  0.002189 -0.013837  0.002057  0.002176 -0.057600  0.035376   \n",
       "\n",
       "            100  \n",
       "0     -0.002442  \n",
       "1     -0.009102  \n",
       "2      0.000338  \n",
       "3     -1.053915  \n",
       "4      0.013337  \n",
       "...         ...  \n",
       "49346 -0.005023  \n",
       "49347  0.004098  \n",
       "49348 -0.005002  \n",
       "49349 -0.016577  \n",
       "49350 -0.013578  \n",
       "\n",
       "[49351 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Owen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#stopword remove\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "en_stops = stopwords.words('english')\n",
    "en_stops.extend([':','A','The',')','(','An','via',',','using','Small','Medium',\n",
    "                 'Large','?',';','in','many','.','>','<','br/','This','including','also',\n",
    "                 'one','two','use','Use','Research','\\'','\\\"'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " ':',\n",
       " 'A',\n",
       " 'The',\n",
       " ')',\n",
       " '(',\n",
       " 'An',\n",
       " 'via',\n",
       " ',',\n",
       " 'using',\n",
       " 'Small',\n",
       " 'Medium',\n",
       " 'Large',\n",
       " '?',\n",
       " ';',\n",
       " 'in',\n",
       " 'many',\n",
       " '.',\n",
       " '>',\n",
       " '<',\n",
       " 'br/',\n",
       " 'This',\n",
       " 'including',\n",
       " 'also',\n",
       " 'one',\n",
       " 'two',\n",
       " 'use',\n",
       " 'Use',\n",
       " 'Research',\n",
       " \"'\",\n",
       " '\"']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[df[0].isin(en_stops)], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>''</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>-0.357776</td>\n",
       "      <td>-1.036951</td>\n",
       "      <td>0.469952</td>\n",
       "      <td>-1.611660</td>\n",
       "      <td>-0.920393</td>\n",
       "      <td>-1.047843</td>\n",
       "      <td>0.812955</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>-0.450508</td>\n",
       "      <td>-0.778890</td>\n",
       "      <td>0.135372</td>\n",
       "      <td>0.134435</td>\n",
       "      <td>-0.894964</td>\n",
       "      <td>0.506059</td>\n",
       "      <td>-1.636131</td>\n",
       "      <td>1.420139</td>\n",
       "      <td>-1.053915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proyecto</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.017918</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>-0.014756</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>-0.023745</td>\n",
       "      <td>-0.009586</td>\n",
       "      <td>-0.014421</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hombre</td>\n",
       "      <td>-0.013173</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>-0.009383</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>-0.008488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>-0.010636</td>\n",
       "      <td>-0.022955</td>\n",
       "      <td>-0.031071</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>-0.012513</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.908531</td>\n",
       "      <td>-0.033861</td>\n",
       "      <td>-0.124413</td>\n",
       "      <td>-0.316041</td>\n",
       "      <td>0.550499</td>\n",
       "      <td>-0.068102</td>\n",
       "      <td>0.063906</td>\n",
       "      <td>0.945967</td>\n",
       "      <td>-0.010683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064064</td>\n",
       "      <td>0.185626</td>\n",
       "      <td>-0.287499</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.060407</td>\n",
       "      <td>0.128885</td>\n",
       "      <td>0.751422</td>\n",
       "      <td>-0.356749</td>\n",
       "      <td>0.473993</td>\n",
       "      <td>-0.148028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>years</td>\n",
       "      <td>-0.991988</td>\n",
       "      <td>-0.052203</td>\n",
       "      <td>-0.746462</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.091673</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>1.027198</td>\n",
       "      <td>-0.095780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173858</td>\n",
       "      <td>0.079364</td>\n",
       "      <td>-0.340901</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.866518</td>\n",
       "      <td>-0.039558</td>\n",
       "      <td>0.529889</td>\n",
       "      <td>-0.528149</td>\n",
       "      <td>0.582073</td>\n",
       "      <td>-0.154103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49346</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.015479</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>-0.005880</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009729</td>\n",
       "      <td>-0.007291</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-0.031664</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.005023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49347</th>\n",
       "      <td>ceramic-polymer</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007756</td>\n",
       "      <td>-0.011556</td>\n",
       "      <td>-0.001872</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.004234</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49348</th>\n",
       "      <td>tape-casting</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009485</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.011675</td>\n",
       "      <td>-0.012465</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.007735</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.042329</td>\n",
       "      <td>0.036488</td>\n",
       "      <td>-0.005002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49349</th>\n",
       "      <td>disc-type</td>\n",
       "      <td>-0.058460</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>-0.020420</td>\n",
       "      <td>-0.003634</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>-0.009637</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019693</td>\n",
       "      <td>-0.009310</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.006744</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>0.038439</td>\n",
       "      <td>-0.016577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>multilayered-type</td>\n",
       "      <td>-0.054010</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.017170</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012833</td>\n",
       "      <td>-0.010574</td>\n",
       "      <td>-0.030285</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>0.035376</td>\n",
       "      <td>-0.013578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49197 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5    \\\n",
       "3                     ''  0.242879 -0.357776 -1.036951  0.469952 -1.611660   \n",
       "4               proyecto  0.006645  0.002655 -0.002004  0.011898  0.009993   \n",
       "5                 hombre -0.013173  0.005983  0.002263  0.010255  0.002010   \n",
       "6                     30 -0.908531 -0.033861 -0.124413 -0.316041  0.550499   \n",
       "7                  years -0.991988 -0.052203 -0.746462  0.054751  0.091673   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "49346                1.9 -0.002337  0.002169 -0.015479  0.009018 -0.012332   \n",
       "49347    ceramic-polymer -0.015645  0.027500  0.015190  0.001908  0.000280   \n",
       "49348       tape-casting -0.035595  0.022825 -0.005805  0.004398 -0.009485   \n",
       "49349          disc-type -0.058460  0.017930 -0.020420 -0.003634 -0.013074   \n",
       "49350  multilayered-type -0.054010  0.014619 -0.017170  0.005641 -0.005823   \n",
       "\n",
       "            6         7         8         9    ...       91        92   \\\n",
       "3     -0.920393 -1.047843  0.812955  0.077639  ...  0.014267 -0.450508   \n",
       "4     -0.003337 -0.017918  0.001710  0.001841  ...  0.001581  0.004362   \n",
       "5     -0.004880 -0.009383  0.012091 -0.008488  ...  0.005712  0.005137   \n",
       "6     -0.068102  0.063906  0.945967 -0.010683  ... -0.064064  0.185626   \n",
       "7      0.003364  0.058668  1.027198 -0.095780  ...  0.173858  0.079364   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "49346 -0.005880 -0.001747 -0.015124 -0.000619  ... -0.009729 -0.007291   \n",
       "49347 -0.001888  0.004398  0.010840  0.003353  ... -0.007756 -0.011556   \n",
       "49348 -0.004525 -0.005787  0.019662  0.010332  ... -0.010189 -0.011675   \n",
       "49349 -0.009637  0.006483  0.024382  0.010641  ... -0.019693 -0.009310   \n",
       "49350  0.001231  0.007013  0.018517  0.011593  ... -0.012833 -0.010574   \n",
       "\n",
       "            93        94        95        96        97        98        99   \\\n",
       "3     -0.778890  0.135372  0.134435 -0.894964  0.506059 -1.636131  1.420139   \n",
       "4     -0.014756 -0.015226 -0.023745 -0.009586 -0.014421 -0.004782  0.034854   \n",
       "5     -0.010636 -0.022955 -0.031071 -0.000086 -0.003307 -0.012513  0.032919   \n",
       "6     -0.287499  0.059508  0.060407  0.128885  0.751422 -0.356749  0.473993   \n",
       "7     -0.340901  0.004598  0.866518 -0.039558  0.529889 -0.528149  0.582073   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49346 -0.004602  0.009725  0.012778  0.003016 -0.001009 -0.031664 -0.003349   \n",
       "49347 -0.001872  0.004398 -0.009889 -0.000199 -0.004234 -0.014100  0.006598   \n",
       "49348 -0.012465  0.002276 -0.001751 -0.007735  0.009182 -0.042329  0.036488   \n",
       "49349 -0.036355  0.006278 -0.007550 -0.006744  0.019674 -0.064233  0.038439   \n",
       "49350 -0.030285  0.002189 -0.013837  0.002057  0.002176 -0.057600  0.035376   \n",
       "\n",
       "            100  \n",
       "3     -1.053915  \n",
       "4      0.013337  \n",
       "5      0.008704  \n",
       "6     -0.148028  \n",
       "7     -0.154103  \n",
       "...         ...  \n",
       "49346 -0.005023  \n",
       "49347  0.004098  \n",
       "49348 -0.005002  \n",
       "49349 -0.016577  \n",
       "49350 -0.013578  \n",
       "\n",
       "[49197 rows x 101 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3        False\n",
       "4        False\n",
       "5        False\n",
       "6         True\n",
       "7        False\n",
       "         ...  \n",
       "49346     True\n",
       "49347    False\n",
       "49348    False\n",
       "49349    False\n",
       "49350    False\n",
       "Name: 0, Length: 49197, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers in the input data\n",
    "get_df= pd.to_numeric(df[0],errors='coerce')\n",
    "\n",
    "bool_series = pd.notnull(get_df) \n",
    "bool_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>-0.908531</td>\n",
       "      <td>-0.033861</td>\n",
       "      <td>-0.124413</td>\n",
       "      <td>-0.316041</td>\n",
       "      <td>0.550499</td>\n",
       "      <td>-0.068102</td>\n",
       "      <td>0.063906</td>\n",
       "      <td>0.945967</td>\n",
       "      <td>-0.010683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064064</td>\n",
       "      <td>0.185626</td>\n",
       "      <td>-0.287499</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.060407</td>\n",
       "      <td>0.128885</td>\n",
       "      <td>0.751422</td>\n",
       "      <td>-0.356749</td>\n",
       "      <td>0.473993</td>\n",
       "      <td>-0.148028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015</td>\n",
       "      <td>-0.368581</td>\n",
       "      <td>-0.188758</td>\n",
       "      <td>-0.178032</td>\n",
       "      <td>0.041550</td>\n",
       "      <td>0.180337</td>\n",
       "      <td>-0.055289</td>\n",
       "      <td>-0.047721</td>\n",
       "      <td>0.315974</td>\n",
       "      <td>0.061549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070776</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>-0.125246</td>\n",
       "      <td>-0.134654</td>\n",
       "      <td>0.005734</td>\n",
       "      <td>0.080504</td>\n",
       "      <td>0.052312</td>\n",
       "      <td>-0.254406</td>\n",
       "      <td>0.280104</td>\n",
       "      <td>0.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.467297</td>\n",
       "      <td>-0.114319</td>\n",
       "      <td>-0.149865</td>\n",
       "      <td>-0.026322</td>\n",
       "      <td>0.291353</td>\n",
       "      <td>-0.068272</td>\n",
       "      <td>0.017396</td>\n",
       "      <td>0.481855</td>\n",
       "      <td>-0.045406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.127144</td>\n",
       "      <td>-0.198767</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.060191</td>\n",
       "      <td>0.084261</td>\n",
       "      <td>0.343665</td>\n",
       "      <td>-0.190612</td>\n",
       "      <td>0.259904</td>\n",
       "      <td>-0.049848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>278</td>\n",
       "      <td>-0.023828</td>\n",
       "      <td>-0.020038</td>\n",
       "      <td>-0.017771</td>\n",
       "      <td>-0.007862</td>\n",
       "      <td>-0.010955</td>\n",
       "      <td>-0.002218</td>\n",
       "      <td>-0.012407</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>-0.009436</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>-0.005081</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.025414</td>\n",
       "      <td>-0.018420</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.004918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>23</td>\n",
       "      <td>0.024488</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>-0.014693</td>\n",
       "      <td>-0.009507</td>\n",
       "      <td>-0.008287</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>-0.013334</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>-0.003292</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.007377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49315</th>\n",
       "      <td>188.14</td>\n",
       "      <td>-0.011424</td>\n",
       "      <td>-0.004595</td>\n",
       "      <td>-0.004161</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>-0.006476</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>-0.019182</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>-0.011256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49316</th>\n",
       "      <td>42.82</td>\n",
       "      <td>-0.012807</td>\n",
       "      <td>-0.013291</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>-0.001942</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>-0.000956</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>-0.008363</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>-0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49321</th>\n",
       "      <td>1.87</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>-0.009973</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>-0.004654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>-0.010620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49344</th>\n",
       "      <td>5737</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>-0.019113</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004384</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>-0.014007</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.003116</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.001171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49346</th>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>-0.015479</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>-0.005880</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009729</td>\n",
       "      <td>-0.007291</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-0.031664</td>\n",
       "      <td>-0.003349</td>\n",
       "      <td>-0.005023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2197 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "6          30 -0.908531 -0.033861 -0.124413 -0.316041  0.550499 -0.068102   \n",
       "17       2015 -0.368581 -0.188758 -0.178032  0.041550  0.180337 -0.055289   \n",
       "20         25 -0.467297 -0.114319 -0.149865 -0.026322  0.291353 -0.068272   \n",
       "96        278 -0.023828 -0.020038 -0.017771 -0.007862 -0.010955 -0.002218   \n",
       "128        23  0.024488 -0.002232 -0.001714  0.021488  0.011271 -0.014693   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "49315  188.14 -0.011424 -0.004595 -0.004161  0.000896  0.017243 -0.000419   \n",
       "49316   42.82 -0.012807 -0.013291  0.000401  0.002789  0.009485  0.004123   \n",
       "49321    1.87  0.003267 -0.004160 -0.002333 -0.009973  0.014447  0.000163   \n",
       "49344    5737  0.003993  0.009449  0.012774  0.014258  0.008403  0.006635   \n",
       "49346     1.9 -0.002337  0.002169 -0.015479  0.009018 -0.012332 -0.005880   \n",
       "\n",
       "            7         8         9    ...       91        92        93   \\\n",
       "6      0.063906  0.945967 -0.010683  ... -0.064064  0.185626 -0.287499   \n",
       "17    -0.047721  0.315974  0.061549  ... -0.070776 -0.123311 -0.125246   \n",
       "20     0.017396  0.481855 -0.045406  ...  0.008336  0.127144 -0.198767   \n",
       "96    -0.012407  0.021379  0.003860  ... -0.000558  0.010200 -0.009436   \n",
       "128   -0.009507 -0.008287  0.000476  ...  0.006840 -0.013334  0.006995   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49315  0.010767  0.009314  0.007421  ...  0.001385 -0.006476  0.000448   \n",
       "49316 -0.001253  0.008915 -0.000658  ...  0.002810 -0.001942  0.001188   \n",
       "49321 -0.005596  0.008476 -0.004654  ...  0.006516  0.002285  0.002840   \n",
       "49344 -0.019113  0.000743 -0.005697  ... -0.004384 -0.003152 -0.014007   \n",
       "49346 -0.001747 -0.015124 -0.000619  ... -0.009729 -0.007291 -0.004602   \n",
       "\n",
       "            94        95        96        97        98        99        100  \n",
       "6      0.059508  0.060407  0.128885  0.751422 -0.356749  0.473993 -0.148028  \n",
       "17    -0.134654  0.005734  0.080504  0.052312 -0.254406  0.280104  0.006660  \n",
       "20     0.003422  0.060191  0.084261  0.343665 -0.190612  0.259904 -0.049848  \n",
       "96     0.003025 -0.005081  0.006926  0.025414 -0.018420  0.011780  0.004918  \n",
       "128    0.005234  0.013535  0.001763  0.005122 -0.003292  0.000789  0.007377  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "49315  0.009714  0.002485 -0.000609  0.003306 -0.019182  0.006983 -0.011256  \n",
       "49316 -0.000956  0.003437  0.002333  0.012245 -0.008363  0.001926 -0.002123  \n",
       "49321  0.001778  0.006985  0.003600  0.006292 -0.001922 -0.002481 -0.010620  \n",
       "49344  0.005720  0.010350 -0.004214 -0.003116 -0.011364  0.011050  0.001171  \n",
       "49346  0.009725  0.012778  0.003016 -0.001009 -0.031664 -0.003349 -0.005023  \n",
       "\n",
       "[2197 rows x 101 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the \"number\" object in in put data\n",
    "df[bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \"number\" object in the dataset\n",
    "df.drop(df.index[df[0].isin(df[bool_series][0])], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>''</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>-0.357776</td>\n",
       "      <td>-1.036951</td>\n",
       "      <td>0.469952</td>\n",
       "      <td>-1.611660</td>\n",
       "      <td>-0.920393</td>\n",
       "      <td>-1.047843</td>\n",
       "      <td>0.812955</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>-0.450508</td>\n",
       "      <td>-0.778890</td>\n",
       "      <td>0.135372</td>\n",
       "      <td>0.134435</td>\n",
       "      <td>-0.894964</td>\n",
       "      <td>0.506059</td>\n",
       "      <td>-1.636131</td>\n",
       "      <td>1.420139</td>\n",
       "      <td>-1.053915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proyecto</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.017918</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>-0.014756</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>-0.023745</td>\n",
       "      <td>-0.009586</td>\n",
       "      <td>-0.014421</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hombre</td>\n",
       "      <td>-0.013173</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>-0.009383</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>-0.008488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>-0.010636</td>\n",
       "      <td>-0.022955</td>\n",
       "      <td>-0.031071</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>-0.012513</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>years</td>\n",
       "      <td>-0.991988</td>\n",
       "      <td>-0.052203</td>\n",
       "      <td>-0.746462</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.091673</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>1.027198</td>\n",
       "      <td>-0.095780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173858</td>\n",
       "      <td>0.079364</td>\n",
       "      <td>-0.340901</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.866518</td>\n",
       "      <td>-0.039558</td>\n",
       "      <td>0.529889</td>\n",
       "      <td>-0.528149</td>\n",
       "      <td>0.582073</td>\n",
       "      <td>-0.154103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>work</td>\n",
       "      <td>-1.714099</td>\n",
       "      <td>0.291870</td>\n",
       "      <td>-0.900320</td>\n",
       "      <td>1.186268</td>\n",
       "      <td>-1.400966</td>\n",
       "      <td>0.459634</td>\n",
       "      <td>0.394019</td>\n",
       "      <td>-0.358624</td>\n",
       "      <td>-0.434260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344437</td>\n",
       "      <td>-0.572115</td>\n",
       "      <td>-0.702981</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.382482</td>\n",
       "      <td>0.830119</td>\n",
       "      <td>-0.537139</td>\n",
       "      <td>-0.581230</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>-0.295305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49345</th>\n",
       "      <td>magneto-photocurrent</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>-0.003609</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.013751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.024917</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49347</th>\n",
       "      <td>ceramic-polymer</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007756</td>\n",
       "      <td>-0.011556</td>\n",
       "      <td>-0.001872</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.004234</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49348</th>\n",
       "      <td>tape-casting</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009485</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.011675</td>\n",
       "      <td>-0.012465</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.007735</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.042329</td>\n",
       "      <td>0.036488</td>\n",
       "      <td>-0.005002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49349</th>\n",
       "      <td>disc-type</td>\n",
       "      <td>-0.058460</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>-0.020420</td>\n",
       "      <td>-0.003634</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>-0.009637</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019693</td>\n",
       "      <td>-0.009310</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.006744</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>0.038439</td>\n",
       "      <td>-0.016577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>multilayered-type</td>\n",
       "      <td>-0.054010</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.017170</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012833</td>\n",
       "      <td>-0.010574</td>\n",
       "      <td>-0.030285</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>0.035376</td>\n",
       "      <td>-0.013578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47000 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4         5    \\\n",
       "3                        ''  0.242879 -0.357776 -1.036951  0.469952 -1.611660   \n",
       "4                  proyecto  0.006645  0.002655 -0.002004  0.011898  0.009993   \n",
       "5                    hombre -0.013173  0.005983  0.002263  0.010255  0.002010   \n",
       "7                     years -0.991988 -0.052203 -0.746462  0.054751  0.091673   \n",
       "9                      work -1.714099  0.291870 -0.900320  1.186268 -1.400966   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "49345  magneto-photocurrent  0.000772 -0.005020 -0.001443  0.014552  0.004731   \n",
       "49347       ceramic-polymer -0.015645  0.027500  0.015190  0.001908  0.000280   \n",
       "49348          tape-casting -0.035595  0.022825 -0.005805  0.004398 -0.009485   \n",
       "49349             disc-type -0.058460  0.017930 -0.020420 -0.003634 -0.013074   \n",
       "49350     multilayered-type -0.054010  0.014619 -0.017170  0.005641 -0.005823   \n",
       "\n",
       "            6         7         8         9    ...       91        92   \\\n",
       "3     -0.920393 -1.047843  0.812955  0.077639  ...  0.014267 -0.450508   \n",
       "4     -0.003337 -0.017918  0.001710  0.001841  ...  0.001581  0.004362   \n",
       "5     -0.004880 -0.009383  0.012091 -0.008488  ...  0.005712  0.005137   \n",
       "7      0.003364  0.058668  1.027198 -0.095780  ...  0.173858  0.079364   \n",
       "9      0.459634  0.394019 -0.358624 -0.434260  ... -0.344437 -0.572115   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "49345 -0.003609 -0.009770 -0.002167 -0.013751  ... -0.003411 -0.002718   \n",
       "49347 -0.001888  0.004398  0.010840  0.003353  ... -0.007756 -0.011556   \n",
       "49348 -0.004525 -0.005787  0.019662  0.010332  ... -0.010189 -0.011675   \n",
       "49349 -0.009637  0.006483  0.024382  0.010641  ... -0.019693 -0.009310   \n",
       "49350  0.001231  0.007013  0.018517  0.011593  ... -0.012833 -0.010574   \n",
       "\n",
       "            93        94        95        96        97        98        99   \\\n",
       "3     -0.778890  0.135372  0.134435 -0.894964  0.506059 -1.636131  1.420139   \n",
       "4     -0.014756 -0.015226 -0.023745 -0.009586 -0.014421 -0.004782  0.034854   \n",
       "5     -0.010636 -0.022955 -0.031071 -0.000086 -0.003307 -0.012513  0.032919   \n",
       "7     -0.340901  0.004598  0.866518 -0.039558  0.529889 -0.528149  0.582073   \n",
       "9     -0.702981  0.036555  0.382482  0.830119 -0.537139 -0.581230  0.365941   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49345 -0.018247  0.006264  0.004802 -0.003425  0.002871 -0.024917  0.007310   \n",
       "49347 -0.001872  0.004398 -0.009889 -0.000199 -0.004234 -0.014100  0.006598   \n",
       "49348 -0.012465  0.002276 -0.001751 -0.007735  0.009182 -0.042329  0.036488   \n",
       "49349 -0.036355  0.006278 -0.007550 -0.006744  0.019674 -0.064233  0.038439   \n",
       "49350 -0.030285  0.002189 -0.013837  0.002057  0.002176 -0.057600  0.035376   \n",
       "\n",
       "            100  \n",
       "3     -1.053915  \n",
       "4      0.013337  \n",
       "5      0.008704  \n",
       "7     -0.154103  \n",
       "9     -0.295305  \n",
       "...         ...  \n",
       "49345  0.003142  \n",
       "49347  0.004098  \n",
       "49348 -0.005002  \n",
       "49349 -0.016577  \n",
       "49350 -0.013578  \n",
       "\n",
       "[47000 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#49351 rows (input rows) vs 47000 rows (after clearning)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.loc[:, df.columns != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.242879</td>\n",
       "      <td>-0.357776</td>\n",
       "      <td>-1.036951</td>\n",
       "      <td>0.469952</td>\n",
       "      <td>-1.611660</td>\n",
       "      <td>-0.920393</td>\n",
       "      <td>-1.047843</td>\n",
       "      <td>0.812955</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>0.406976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>-0.450508</td>\n",
       "      <td>-0.778890</td>\n",
       "      <td>0.135372</td>\n",
       "      <td>0.134435</td>\n",
       "      <td>-0.894964</td>\n",
       "      <td>0.506059</td>\n",
       "      <td>-1.636131</td>\n",
       "      <td>1.420139</td>\n",
       "      <td>-1.053915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>0.009993</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.017918</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.021023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>-0.014756</td>\n",
       "      <td>-0.015226</td>\n",
       "      <td>-0.023745</td>\n",
       "      <td>-0.009586</td>\n",
       "      <td>-0.014421</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>0.034854</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.013173</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>-0.009383</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>-0.008488</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>-0.010636</td>\n",
       "      <td>-0.022955</td>\n",
       "      <td>-0.031071</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>-0.012513</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.991988</td>\n",
       "      <td>-0.052203</td>\n",
       "      <td>-0.746462</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.091673</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.058668</td>\n",
       "      <td>1.027198</td>\n",
       "      <td>-0.095780</td>\n",
       "      <td>0.227966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173858</td>\n",
       "      <td>0.079364</td>\n",
       "      <td>-0.340901</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.866518</td>\n",
       "      <td>-0.039558</td>\n",
       "      <td>0.529889</td>\n",
       "      <td>-0.528149</td>\n",
       "      <td>0.582073</td>\n",
       "      <td>-0.154103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.714099</td>\n",
       "      <td>0.291870</td>\n",
       "      <td>-0.900320</td>\n",
       "      <td>1.186268</td>\n",
       "      <td>-1.400966</td>\n",
       "      <td>0.459634</td>\n",
       "      <td>0.394019</td>\n",
       "      <td>-0.358624</td>\n",
       "      <td>-0.434260</td>\n",
       "      <td>-0.655833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344437</td>\n",
       "      <td>-0.572115</td>\n",
       "      <td>-0.702981</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.382482</td>\n",
       "      <td>0.830119</td>\n",
       "      <td>-0.537139</td>\n",
       "      <td>-0.581230</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>-0.295305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49345</th>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>0.014552</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>-0.003609</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>-0.013751</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003411</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.024917</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.003142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49347</th>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007756</td>\n",
       "      <td>-0.011556</td>\n",
       "      <td>-0.001872</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009889</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.004234</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49348</th>\n",
       "      <td>-0.035595</td>\n",
       "      <td>0.022825</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.009485</td>\n",
       "      <td>-0.004525</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.011675</td>\n",
       "      <td>-0.012465</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>-0.001751</td>\n",
       "      <td>-0.007735</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>-0.042329</td>\n",
       "      <td>0.036488</td>\n",
       "      <td>-0.005002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49349</th>\n",
       "      <td>-0.058460</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>-0.020420</td>\n",
       "      <td>-0.003634</td>\n",
       "      <td>-0.013074</td>\n",
       "      <td>-0.009637</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019693</td>\n",
       "      <td>-0.009310</td>\n",
       "      <td>-0.036355</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>-0.006744</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>0.038439</td>\n",
       "      <td>-0.016577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49350</th>\n",
       "      <td>-0.054010</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>-0.017170</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.018517</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012833</td>\n",
       "      <td>-0.010574</td>\n",
       "      <td>-0.030285</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>0.035376</td>\n",
       "      <td>-0.013578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7    \\\n",
       "3      0.242879 -0.357776 -1.036951  0.469952 -1.611660 -0.920393 -1.047843   \n",
       "4      0.006645  0.002655 -0.002004  0.011898  0.009993 -0.003337 -0.017918   \n",
       "5     -0.013173  0.005983  0.002263  0.010255  0.002010 -0.004880 -0.009383   \n",
       "7     -0.991988 -0.052203 -0.746462  0.054751  0.091673  0.003364  0.058668   \n",
       "9     -1.714099  0.291870 -0.900320  1.186268 -1.400966  0.459634  0.394019   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49345  0.000772 -0.005020 -0.001443  0.014552  0.004731 -0.003609 -0.009770   \n",
       "49347 -0.015645  0.027500  0.015190  0.001908  0.000280 -0.001888  0.004398   \n",
       "49348 -0.035595  0.022825 -0.005805  0.004398 -0.009485 -0.004525 -0.005787   \n",
       "49349 -0.058460  0.017930 -0.020420 -0.003634 -0.013074 -0.009637  0.006483   \n",
       "49350 -0.054010  0.014619 -0.017170  0.005641 -0.005823  0.001231  0.007013   \n",
       "\n",
       "            8         9         10   ...       91        92        93   \\\n",
       "3      0.812955  0.077639  0.406976  ...  0.014267 -0.450508 -0.778890   \n",
       "4      0.001710  0.001841  0.021023  ...  0.001581  0.004362 -0.014756   \n",
       "5      0.012091 -0.008488  0.028956  ...  0.005712  0.005137 -0.010636   \n",
       "7      1.027198 -0.095780  0.227966  ...  0.173858  0.079364 -0.340901   \n",
       "9     -0.358624 -0.434260 -0.655833  ... -0.344437 -0.572115 -0.702981   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49345 -0.002167 -0.013751  0.003425  ... -0.003411 -0.002718 -0.018247   \n",
       "49347  0.010840  0.003353  0.003227  ... -0.007756 -0.011556 -0.001872   \n",
       "49348  0.019662  0.010332  0.004159  ... -0.010189 -0.011675 -0.012465   \n",
       "49349  0.024382  0.010641  0.008010  ... -0.019693 -0.009310 -0.036355   \n",
       "49350  0.018517  0.011593  0.013623  ... -0.012833 -0.010574 -0.030285   \n",
       "\n",
       "            94        95        96        97        98        99        100  \n",
       "3      0.135372  0.134435 -0.894964  0.506059 -1.636131  1.420139 -1.053915  \n",
       "4     -0.015226 -0.023745 -0.009586 -0.014421 -0.004782  0.034854  0.013337  \n",
       "5     -0.022955 -0.031071 -0.000086 -0.003307 -0.012513  0.032919  0.008704  \n",
       "7      0.004598  0.866518 -0.039558  0.529889 -0.528149  0.582073 -0.154103  \n",
       "9      0.036555  0.382482  0.830119 -0.537139 -0.581230  0.365941 -0.295305  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "49345  0.006264  0.004802 -0.003425  0.002871 -0.024917  0.007310  0.003142  \n",
       "49347  0.004398 -0.009889 -0.000199 -0.004234 -0.014100  0.006598  0.004098  \n",
       "49348  0.002276 -0.001751 -0.007735  0.009182 -0.042329  0.036488 -0.005002  \n",
       "49349  0.006278 -0.007550 -0.006744  0.019674 -0.064233  0.038439 -0.016577  \n",
       "49350  0.002189 -0.013837  0.002057  0.002176 -0.057600  0.035376 -0.013578  \n",
       "\n",
       "[47000 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_array=new_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24287882, -0.35777566, -1.03695107, ..., -1.63613141,\n",
       "         1.42013896, -1.05391538],\n",
       "       [ 0.0066447 ,  0.00265451, -0.00200435, ..., -0.00478246,\n",
       "         0.03485362,  0.01333732],\n",
       "       [-0.01317317,  0.00598321,  0.00226336, ..., -0.01251267,\n",
       "         0.03291901,  0.00870373],\n",
       "       ...,\n",
       "       [-0.0355951 ,  0.02282503, -0.00580515, ..., -0.04232861,\n",
       "         0.0364881 , -0.00500166],\n",
       "       [-0.05846043,  0.01793048, -0.02041978, ..., -0.06423273,\n",
       "         0.03843851, -0.01657687],\n",
       "       [-0.05400997,  0.01461924, -0.01717002, ..., -0.05760012,\n",
       "         0.03537645, -0.01357833]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the cossin similarity matrix for input data\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim=cosine_similarity(matrix_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47000, 47000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similirity: 9.744353182522044\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#calcualte the euclidean for input data\n",
    "npvec1, npvec2 = np.array(matrix_array[0]), np.array(matrix_array[1])\n",
    "similirity=math.sqrt(((npvec1 - npvec2) ** 2).sum())\n",
    "print('similirity:',similirity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similirity2: 0.8015069832117309\n"
     ]
    }
   ],
   "source": [
    " #cossin \n",
    "def cos_sim(vector_a, vector_b):\n",
    "\n",
    "    vector_a = np.mat(vector_a)\n",
    "    vector_b = np.mat(vector_b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom #\n",
    "    sim = 0.5 + 0.5 * cos # put the cos into range of [-1,1]\n",
    "    return sim\n",
    " \n",
    "\n",
    "vector_a, vector_b = np.array(matrix_array[0]), np.array(matrix_array[1])\n",
    "similirity2=cos_sim(vector_a, vector_b)\n",
    "print('similirity2:',similirity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24287882, -0.35777566, -1.03695107,  0.46995163, -1.61165976,\n",
       "       -0.92039329, -1.04784286,  0.8129555 ,  0.07763919,  0.40697613,\n",
       "        1.32716989, -1.00840843, -0.15525781,  0.11751208,  0.19408521,\n",
       "        0.84074271, -0.53778124,  0.15768929,  0.4488987 , -0.72926593,\n",
       "       -0.58345252,  1.75402582, -0.30448955, -0.30034822, -0.24734451,\n",
       "        0.30986801, -0.41497129, -0.56778306, -0.15473457,  0.74023688,\n",
       "        0.80535078, -0.2335635 ,  0.10564765,  1.49808145,  1.46376419,\n",
       "       -0.86561412,  0.54836804, -0.39815638, -0.86454266,  2.64108634,\n",
       "        0.11136475,  1.32302916,  0.93941891, -0.10490359,  0.39063081,\n",
       "       -1.39327967,  0.47405505,  0.07939219,  0.83572221,  0.15436947,\n",
       "       -0.22521049,  0.62853444, -2.09202147, -0.57162815,  0.22656937,\n",
       "       -0.96752751,  0.26741514,  0.92161977,  0.13609155,  1.18648362,\n",
       "       -2.32363248,  1.79173434,  1.15440869,  0.21538702,  0.80555099,\n",
       "       -0.39522707, -1.44575834, -0.1863111 ,  1.53413689,  2.2543056 ,\n",
       "       -1.69351673,  0.20529205, -0.72484785, -0.95196629, -0.49434829,\n",
       "       -0.20452081,  0.82215869,  0.51757509, -0.83654445,  1.44408953,\n",
       "       -0.07865094,  1.91671348, -1.12310088, -1.71567166, -2.28257775,\n",
       "        0.04804321, -0.7737034 , -1.26426613,  0.81779319, -0.04456622,\n",
       "        0.01426738, -0.45050836, -0.77889025,  0.13537243,  0.13443527,\n",
       "       -0.8949635 ,  0.50605899, -1.63613141,  1.42013896, -1.05391538])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaking sentences\n",
    "import re\n",
    "def preprocess(raw_text):\n",
    "\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n",
    "\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clustering', 'project', 'topics', 'bibliometrics']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demo\n",
    "preprocess(\"our project is clustering the topics for bibliometrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>good</td>\n",
       "      <td>-0.605064</td>\n",
       "      <td>0.750338</td>\n",
       "      <td>-0.357561</td>\n",
       "      <td>0.559628</td>\n",
       "      <td>0.372538</td>\n",
       "      <td>-0.225532</td>\n",
       "      <td>0.20982</td>\n",
       "      <td>0.322781</td>\n",
       "      <td>-0.397406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429263</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>0.830147</td>\n",
       "      <td>0.928995</td>\n",
       "      <td>0.628726</td>\n",
       "      <td>0.62987</td>\n",
       "      <td>-0.647675</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.498201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "1040  good -0.605064  0.750338 -0.357561  0.559628  0.372538 -0.225532   \n",
       "\n",
       "          7         8         9    ...       91        92        93   \\\n",
       "1040  0.20982  0.322781 -0.397406  ...  0.429263 -0.070537 -0.025906   \n",
       "\n",
       "           94        95        96       97        98        99        100  \n",
       "1040  0.830147  0.928995  0.628726  0.62987 -0.647675  0.008297  0.498201  \n",
       "\n",
       "[1 rows x 101 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the similarity between sentences\n",
    "df.loc[df[0] == 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6050638 ,  0.75033778, -0.35756069,  0.55962807,  0.37253818,\n",
       "       -0.22553228,  0.20982015,  0.32278138, -0.39740622, -0.11251175,\n",
       "        0.60983092,  0.66415328, -0.6410203 , -0.2465214 ,  0.45571682,\n",
       "       -1.41686964,  0.93193793,  0.31855482,  0.33465785,  0.28014287,\n",
       "       -0.22833929,  0.30800176,  0.91108513, -0.14133626,  0.31309778,\n",
       "        1.16345549,  0.43320203, -1.11014891,  0.81647634,  0.90124726,\n",
       "        0.88448638,  0.37285435,  0.43028617,  0.9584955 , -0.99939501,\n",
       "        0.33037791,  0.2496722 , -0.56141979, -0.22573456,  0.76829439,\n",
       "        0.41068336,  0.1598134 , -0.70986271,  0.47615069,  0.724325  ,\n",
       "        0.84300834,  0.37968373, -0.49013177,  0.20500499, -0.47323036,\n",
       "       -0.10184456, -0.10935862, -0.90881866, -0.48304382, -0.17107232,\n",
       "       -0.44038266,  0.58729094,  0.89631611,  0.53794736,  0.28038544,\n",
       "       -1.0682838 ,  0.51772404,  0.23506904,  0.07441196, -1.44060099,\n",
       "        0.65947533, -0.20023557, -0.08428721,  0.29650548,  0.08426941,\n",
       "       -0.15826078, -0.15145265, -0.40774328,  0.87505573, -0.27823785,\n",
       "       -0.79318935, -0.66308147, -0.10427295,  0.80628723, -0.90404445,\n",
       "       -1.44805849, -0.0762731 ,  1.58461952, -0.0089359 ,  1.06948543,\n",
       "       -0.38591147,  0.65576547,  0.91068387,  0.10667817,  1.08188188,\n",
       "        0.42926317, -0.07053722, -0.02590603,  0.83014715,  0.92899531,\n",
       "        0.62872577,  0.62987012, -0.64767528,  0.00829729,  0.49820122])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the word vectors for word \"good\"\n",
    "good=np.array(df.loc[df[0] == 'good'])[0][1:]\n",
    "good.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between ss1 and ss2 is:  59.14 %\n"
     ]
    }
   ],
   "source": [
    "# calculate the similarity between sentences ss1 and ss2\n",
    "ss1=\"we have an apple\"\n",
    "ss2=\"the apple is owned by us\"\n",
    "import scipy\n",
    "vector_11 = np.mean([df.loc[df[0] == word].values[0][1:].astype(float) for word in preprocess(ss1)],axis=0)\n",
    "vector_22 = np.mean([df.loc[df[0] == word].values[0][1:].astype(float) for word in preprocess(ss2)],axis=0)\n",
    "cosine = scipy.spatial.distance.cosine(vector_11, vector_22)\n",
    "print('similarity between ss1 and ss2 is: ',round((1-cosine)*100,2),'%')\n",
    "#good person vs research person ==58%\n",
    "#good person vs nice person ==78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02368197,  0.01278864, -0.00232564,  0.00274144, -0.02015077,\n",
       "        0.00110137, -0.01028255,  0.0060642 ,  0.00731735,  0.0118547 ,\n",
       "        0.02492996,  0.00098029, -0.00765314, -0.00194057, -0.00538484,\n",
       "       -0.01603745,  0.0012542 ,  0.00446832,  0.01631443,  0.00610901,\n",
       "       -0.01633447,  0.02361696,  0.01516676, -0.01566313,  0.02004468,\n",
       "        0.01651367,  0.01469453, -0.02495989,  0.00636395,  0.0195251 ,\n",
       "        0.0110039 ,  0.00842122,  0.00138341,  0.00940142,  0.00657012,\n",
       "        0.01695958, -0.0001793 , -0.01667115, -0.00138245,  0.01436788,\n",
       "        0.01756926, -0.00417639, -0.00837124, -0.0046242 , -0.00492918,\n",
       "       -0.0006242 ,  0.00897326, -0.0044639 ,  0.01209431,  0.01010753,\n",
       "        0.00894983,  0.00830819, -0.00972463,  0.00705869,  0.01971793,\n",
       "       -0.00327531,  0.00520551,  0.01450831,  0.00872251,  0.01787499,\n",
       "       -0.00039529,  0.0125823 , -0.00185692,  0.01439286, -0.00532308,\n",
       "        0.00165117,  0.00140874,  0.00275977,  0.00675921,  0.00897416,\n",
       "       -0.02669232,  0.01351255,  0.01789122, -0.00969961,  0.01267988,\n",
       "       -0.0163118 ,  0.002262  ,  0.01626016,  0.00372956,  0.00472341,\n",
       "       -0.00135268,  0.00632633, -0.00501945, -0.01776172,  0.0026017 ,\n",
       "        0.01299183, -0.00723185,  0.00823049,  0.01011976,  0.02872582,\n",
       "       -0.01049446,  0.00249932, -0.0071212 , -0.00357453,  0.00136333,\n",
       "       -0.00055572, -0.00091068, -0.01569938, -0.00371219,  0.00029963])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector_11 is taking the average of word vectors of each words in ss1\n",
    "vector_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3636d3334e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#db = DBSCAN(eps=0.5, min_samples=5).fit(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mcore_samples_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcore_samples_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_sample_indices_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'options' is not defined"
     ]
    }
   ],
   "source": [
    "#DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = matrix_array\n",
    "db = DBSCAN(eps=0.5, min_samples=5).fit(X)\n",
    "\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 16816, 0: 30158, 1: 4, 2: 4, 3: 3, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 if -1 in labels else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_samples_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 9\n",
      "Estimated number of noise points: 16816\n",
      "Silhouette Coefficient: -0.067\n"
     ]
    }
   ],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "plt.figure(figsize=(60,60))\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    my_members = labels == k\n",
    "    #cluster_center = cluster_centers[k]\n",
    "    plt.plot(X[my_members, 0], X[my_members, 1], col + '.')\n",
    "    #plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,\n",
    "             #markeredgecolor='k', markersize=14)\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for eps in np.arange(0.1, 50, 0.1):\n",
    "    dbscan_model = None\n",
    "    labels = None\n",
    "    n_clusters_=None\n",
    "    n_noise_=None\n",
    "    unique = None\n",
    "    counts = None\n",
    "\n",
    "    dbscan_model = DBSCAN(eps=eps, min_samples=3, metric_params=None, algorithm=\"auto\", leaf_size=30, p=None, n_jobs=1)\n",
    "    labels = dbscan_model.fit_predict(X)\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(dict(zip(unique, counts)))\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    print('Estimated number of noise points: %d' % n_noise_)\n",
    "    print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Consider linear time MMD with a linear kernel:\n",
    "# K(f(x), f(y)) = f(x)^Tf(y)\n",
    "# h(z_i, z_j) = k(x_i, x_j) + k(y_i, y_j) - k(x_i, y_j) - k(x_j, y_i)\n",
    "#             = [f(x_i) - f(y_i)]^T[f(x_j) - f(y_j)]\n",
    "#\n",
    "# f_of_X: batch_size * k\n",
    "# f_of_Y: batch_size * k\n",
    "def mmd_linear(f_of_X, f_of_Y):\n",
    "    delta = f_of_X - f_of_Y\n",
    "    loss = torch.mean(torch.mm(delta, torch.transpose(delta, 0, 1)))\n",
    "    return loss\n",
    "\n",
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    L2_distance = ((total0-total1)**2).sum(2)\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)#/len(kernel_val)\n",
    "\n",
    "\n",
    "def mmd_rbf_accelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    loss = 0\n",
    "    for i in range(batch_size):\n",
    "        s1, s2 = i, (i+1)%batch_size\n",
    "        t1, t2 = s1+batch_size, s2+batch_size\n",
    "        loss += kernels[s1, s2] + kernels[t1, t2]\n",
    "        loss -= kernels[s1, t2] + kernels[s2, t1]\n",
    "    return loss / float(batch_size)\n",
    "\n",
    "def mmd_rbf_noaccelerate(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY -YX)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1bf0b4b4f524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmmd_rbf_noaccelerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatrix_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-7194b8b58a30>\u001b[0m in \u001b[0;36mmmd_rbf_noaccelerate\u001b[1;34m(source, target, kernel_mul, kernel_num, fix_sigma)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmmd_rbf_noaccelerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_mul\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfix_sigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     kernels = guassian_kernel(source, target,\n\u001b[0;32m     51\u001b[0m                               kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "mmd_rbf_noaccelerate(matrix_array[0],matrix_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0e03c7d7e3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "matrix_array[0].size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.array([[1, 2, 3],[4,5,6]])\n",
    "torch.from_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-9df3712d607f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-af584aadf138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0marr0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0marr1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmmd_rbf_accelerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-7194b8b58a30>\u001b[0m in \u001b[0;36mmmd_rbf_accelerate\u001b[1;34m(source, target, kernel_mul, kernel_num, fix_sigma)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     kernels = guassian_kernel(source, target,\n\u001b[1;32m---> 39\u001b[1;33m         kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-7194b8b58a30>\u001b[0m in \u001b[0;36mguassian_kernel\u001b[1;34m(source, target, kernel_mul, kernel_num, fix_sigma)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtotal0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mtotal1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mL2_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtotal1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "arr0=torch.tensor(matrix_array[0])\n",
    "arr1=torch.tensor(matrix_array[1])\n",
    "mmd_rbf_accelerate(arr0,arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano.tensor import slinalg\n",
    "\n",
    "_eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quadratic-time MMD with Gaussian RBF kernel\n",
    "\n",
    "def rbf_mmd2(X, Y, sigma=0, biased=True):\n",
    "    \n",
    "    gamma = 1 / (2 * sigma**2)\n",
    "\n",
    "    XX = T.dot(X, X.T)\n",
    "    XY = T.dot(X, Y.T)\n",
    "    YY = T.dot(Y, Y.T)\n",
    "\n",
    "    X_sqnorms = T.diagonal(XX)\n",
    "    Y_sqnorms = T.diagonal(YY)\n",
    "\n",
    "    K_XY = T.exp(-gamma * (\n",
    "            -2 * XY + X_sqnorms[:, np.newaxis] + Y_sqnorms[np.newaxis, :]))\n",
    "    K_XX = T.exp(-gamma * (\n",
    "            -2 * XX + X_sqnorms[:, np.newaxis] + X_sqnorms[np.newaxis, :]))\n",
    "    K_YY = T.exp(-gamma * (\n",
    "            -2 * YY + Y_sqnorms[:, np.newaxis] + Y_sqnorms[np.newaxis, :]))\n",
    "\n",
    "    if biased:\n",
    "        mmd2 = K_XX.mean() + K_YY.mean() - 2 * K_XY.mean()\n",
    "    else:\n",
    "        m = K_XX.shape[0]\n",
    "        n = K_YY.shape[0]\n",
    "\n",
    "        mmd2 = ((K_XX.sum() - m) / (m * (m - 1))\n",
    "              + (K_YY.sum() - n) / (n * (n - 1))\n",
    "              - 2 * K_XY.mean())\n",
    "    \n",
    "    return mmd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=np.reshape(matrix_array[0],(100,1))\n",
    "test2=np.reshape(matrix_array[1],(100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "Xth, Yth = T.matrices('X', 'Y')\n",
    "sigmath = T.scalar('sigma')\n",
    "fn = theano.function([Xth, Yth, sigmath],rbf_mmd2(Xth, Yth, sigma=sigmath))\n",
    "mmd2 = fn(test1,test2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.15208526)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MMD(X,Y):\n",
    "    import theano\n",
    "    input1=np.reshape(X,(100,1))\n",
    "    input2=np.reshape(Y,(100,1))\n",
    "    Xth, Yth = T.matrices('X', 'Y')\n",
    "    sigmath = T.scalar('sigma')\n",
    "    fn = theano.function([Xth, Yth, sigmath],rbf_mmd2(Xth, Yth, sigma=sigmath))\n",
    "    mmd2 = fn(input1,input2, 1)\n",
    "    \n",
    "    return float(mmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=get_MMD(matrix_array[0],matrix_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15208526485954477"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = matrix_array\n",
    "db = DBSCAN(eps=0.2, min_samples=5, metric=get_MMD).fit(X)\n",
    "\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
